{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import optuna\n",
    "from optuna import logging\n",
    "from keras.optimizers import Adam\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "path = \"../../dane/8CPU_20RAM/3600s/7_merged.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załaduj dane\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie stosujemy one-hod encoding (kolumny z 0 i 1) bo zwiększy to bardzo czas obliczen\n",
    "for col in ['replicaId', 'endpointUrl_methods']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodajemy skalowanie dla wybranych kolumn\n",
    "features_to_scale = ['queueSizeForward_methods', 'queueSizeBack_methods',\n",
    "                     'cpuUsage_stock', 'memoryUsage_stock',\n",
    "                     'applicationTime_trading', 'databaseTime_trading',\n",
    "                     'numberOfSellOffers_trading', 'numberOfBuyOffers_trading']\n",
    "scaler = StandardScaler() #StandardScaler()MinMaxScaler\n",
    "for col in features_to_scale:\n",
    "    df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kodowanie kolumny 'test'\n",
    "le_test = LabelEncoder()\n",
    "df['test'] = le_test.fit_transform(df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybór cech\n",
    "features = [\n",
    "            # 'timestamp',\n",
    "            # 'apiTime_methods',\n",
    "            # 'applicationTime_methods',\n",
    "            # 'databaseTime_methods',\n",
    "            # 'endpointUrl_methods',\n",
    "            # 'queueSizeForward_methods',\n",
    "            # 'queueSizeBack_methods',\n",
    "            'cpuUsage_stock',\n",
    "            'memoryUsage_stock',\n",
    "            # 'applicationTime_trading',\n",
    "            # 'databaseTime_trading',\n",
    "            # 'numberOfSellOffers_trading',\n",
    "            # 'numberOfBuyOffers_trading',\n",
    "            # 'cpuUsage_traffic',\n",
    "            # 'memoryUsage_traffic',\n",
    "            # 'replicaId'\n",
    "            ]\n",
    "df_features = df[features]\n",
    "\n",
    "# Kopiowanie danych\n",
    "df_encoded = df_features.copy()\n",
    "df_encoded['test'] = df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(X, y, window_size, step_size):\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "\n",
    "    # Przesuń okno po danych\n",
    "    for i in range(0, len(X) - window_size, step_size):\n",
    "        # Utwórz okno danych\n",
    "        X_window = X.iloc[i:i + window_size]\n",
    "        # Utwórz etykietę dla okna (etykieta ostatniej obserwacji w oknie)\n",
    "        y_window = y.iloc[i + window_size]\n",
    "\n",
    "        X_windows.append(X_window.values)\n",
    "        y_windows.append(y_window)\n",
    "\n",
    "    return np.array(X_windows), np.array(y_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stwórz puste listy do przechowywania danych treningowych i testowych\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5000\n",
    "step_size = 1000\n",
    "# Dla każdego unikalnego pudełka\n",
    "for box in df_encoded['test'].unique():\n",
    "    # Wybierz tylko rekordy dla tego pudełka\n",
    "    box_data = df_encoded[df_encoded['test'] == box]\n",
    "    \n",
    "    # Oblicz punkt podziału (80% danych)\n",
    "    split_point = int(len(box_data) * 0.8)\n",
    "    \n",
    "    # Dodaj pierwsze 80% rekordów do danych treningowych\n",
    "    X_train_box = box_data.drop('test', axis=1).iloc[:split_point]\n",
    "    y_train_box = box_data['test'].iloc[:split_point]\n",
    "    \n",
    "    # Dodaj ostatnie 20% rekordów do danych testowych\n",
    "    X_test_box = box_data.drop('test', axis=1).iloc[split_point:]\n",
    "    y_test_box = box_data['test'].iloc[split_point:]\n",
    "    \n",
    "    # Stwórz okienka dla danych treningowych\n",
    "    X_train_windows, y_train_windows = create_windows(X_train_box, y_train_box, window_size, step_size)\n",
    "    \n",
    "    # Stwórz okienka dla danych testowych\n",
    "    X_test_windows, y_test_windows = create_windows(X_test_box, y_test_box, window_size, step_size)\n",
    "    \n",
    "    # Dodaj okienka do list\n",
    "    X_train.append(X_train_windows)\n",
    "    y_train.append(y_train_windows)\n",
    "    X_test.append(X_test_windows)\n",
    "    y_test.append(y_test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Połączenie danych treningowych dla wszystkich pudełek\n",
    "X_train_combined = np.concatenate(X_train, axis=0)\n",
    "y_train_combined = np.concatenate(y_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zakodowanie etykiet w formacie one-hot encoding\n",
    "y_train_combined_encoded = to_categorical(y_train_combined, num_classes=len(df['test'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_combined = np.concatenate(X_test, axis=0)\n",
    "y_test_combined = np.concatenate(y_test, axis=0)\n",
    "y_test_encoded_combined = to_categorical(y_test_combined, num_classes=len(df['test'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_units:int, n_layers: int, learning_rate: float):\n",
    "    model = Sequential()\n",
    "    return_sequences = True if n_layers > 0 else False  # Jeśli istnieją warstwy LSTM, pierwsza warstwa GRU musi zwracać sekwencje\n",
    "    model.add(GRU(n_units, return_sequences=return_sequences, input_shape=(window_size, X_train_combined.shape[2])))\n",
    "    for i in range(n_layers):\n",
    "        return_sequences = True if i < n_layers - 1 else False  # ostatnia warstwa LSTM ma return_sequences=False\n",
    "        model.add(LSTM(n_units, return_sequences=return_sequences))\n",
    "    model.add(Dense(len(df['test'].unique()), activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    n_units = trial.suggest_int(\"n_units\", 5, 175)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_int('batch_size', 5, 125)\n",
    "    epochs = trial.suggest_int('epochs', 3, 15)\n",
    "    n_layers = trial.suggest_int('n_layers', 0, 2) \n",
    "    # Build and compile the model\n",
    "    model = create_model(n_units, n_layers, lr)\n",
    "\n",
    "    # Early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "    print('start ', n_units, lr, batch_size, epochs,n_layers)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_combined, y_train_combined_encoded, \n",
    "                        validation_data=(X_test_combined, y_test_encoded_combined),\n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        callbacks=[es, TFKerasPruningCallback(trial, 'val_loss')])\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test_combined, y_test_encoded_combined, verbose=0)\n",
    "\n",
    "    print(f\"Trial {trial.number}, values: {trial.params}, result: {score[1]}\")\n",
    "\n",
    "    return score[1]  # return validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.get_logger('optuna')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 01:09:59,430]\u001b[0m A new study created in memory with name: no-name-2d73c4ac-ed3b-4429-99bc-cb9a38636979\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start  86 0.008049637669161341 92 8 1\n",
      "Epoch 1/8\n",
      "30/30 [==============================] - 6970s 236s/step - loss: 1.5957 - accuracy: 0.3366 - val_loss: 1.4678 - val_accuracy: 0.4000\n",
      "Epoch 2/8\n",
      "30/30 [==============================] - 8375s 281s/step - loss: 1.2863 - accuracy: 0.4843 - val_loss: 1.4282 - val_accuracy: 0.3818\n",
      "Epoch 3/8\n",
      "30/30 [==============================] - 8510s 284s/step - loss: 1.2076 - accuracy: 0.5201 - val_loss: 1.2528 - val_accuracy: 0.4879\n",
      "Epoch 4/8\n",
      "30/30 [==============================] - 8659s 289s/step - loss: 1.2726 - accuracy: 0.4978 - val_loss: 1.4398 - val_accuracy: 0.3061\n",
      "Epoch 5/8\n",
      "30/30 [==============================] - 8687s 290s/step - loss: 1.1576 - accuracy: 0.5336 - val_loss: 1.7077 - val_accuracy: 0.4379\n",
      "Epoch 6/8\n",
      "30/30 [==============================] - 8750s 292s/step - loss: 1.0444 - accuracy: 0.5899 - val_loss: 1.4059 - val_accuracy: 0.4545\n",
      "Epoch 7/8\n",
      "30/30 [==============================] - 8869s 296s/step - loss: 0.9505 - accuracy: 0.6513 - val_loss: 1.6617 - val_accuracy: 0.4182\n",
      "Epoch 8/8\n",
      "30/30 [==============================] - 9071s 303s/step - loss: 1.5991 - accuracy: 0.3819 - val_loss: 1.5907 - val_accuracy: 0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 20:02:11,486]\u001b[0m Trial 0 finished with value: 0.41969695687294006 and parameters: {'n_units': 86, 'lr': 0.008049637669161341, 'batch_size': 92, 'epochs': 8, 'n_layers': 1}. Best is trial 0 with value: 0.41969695687294006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0, values: {'n_units': 86, 'lr': 0.008049637669161341, 'batch_size': 92, 'epochs': 8, 'n_layers': 1}, result: 0.41969695687294006\n",
      "start  37 0.0009817388994273065 28 4 2\n",
      "Epoch 1/4\n",
      "98/98 [==============================] - 776s 8s/step - loss: 1.6365 - accuracy: 0.3180 - val_loss: 1.4944 - val_accuracy: 0.3455\n",
      "Epoch 2/4\n",
      "98/98 [==============================] - 699s 7s/step - loss: 1.3090 - accuracy: 0.4645 - val_loss: 1.3902 - val_accuracy: 0.4273\n",
      "Epoch 3/4\n",
      "98/98 [==============================] - 701s 7s/step - loss: 1.2306 - accuracy: 0.5069 - val_loss: 1.4764 - val_accuracy: 0.3591\n",
      "Epoch 4/4\n",
      "98/98 [==============================] - 703s 7s/step - loss: 1.1410 - accuracy: 0.5563 - val_loss: 1.3673 - val_accuracy: 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 20:50:29,517]\u001b[0m Trial 1 finished with value: 0.49848484992980957 and parameters: {'n_units': 37, 'lr': 0.0009817388994273065, 'batch_size': 28, 'epochs': 4, 'n_layers': 2}. Best is trial 1 with value: 0.49848484992980957.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, values: {'n_units': 37, 'lr': 0.0009817388994273065, 'batch_size': 28, 'epochs': 4, 'n_layers': 2}, result: 0.49848484992980957\n",
      "start  124 0.008697099267550874 78 10 1\n",
      "Epoch 1/10\n",
      "14/36 [==========>...................] - ETA: 2:15:43 - loss: 1.7784 - accuracy: 0.2500"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rezultaty\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    y_test_encoded = to_categorical(y_test[i], num_classes=len(df['test'].unique()))\n",
    "    score = grid.score(X_test[i], y_test_encoded)\n",
    "    print(f\"Test {i+1}: Score = {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
